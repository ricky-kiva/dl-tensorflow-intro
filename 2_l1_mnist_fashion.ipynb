{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q5PMuXbEeZtV",
        "cE4WdNaze6LX"
      ],
      "authorship_tag": "ABX9TyNGrErMVRFpJgS3IZvq9uOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricky-kiva/dl-tensorflow-intro/blob/main/2_l1_mnist_fashion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MNIST Fashion Model**"
      ],
      "metadata": {
        "id": "HKcMjPn9eGap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq66_vbvUtmY",
        "outputId": "130ad0fa-6af3-4d95-acc3-2349ff69de32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) is a collection of grayscale 28x28 pixel fashion images\n",
        "\n",
        "Each images is associated with a label in this table:\n",
        "\n",
        "| Label | Desc |\n",
        "| --- | --- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |"
      ],
      "metadata": {
        "id": "BisyDkpuVLC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST dataset is available directly in the [tf.keras.datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) API"
      ],
      "metadata": {
        "id": "FKKoL89RV0AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load Fashion MNIST dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "g8hOxmUxV7Dt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load training & test split from the dataset\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkiaRFKhWShS",
        "outputId": "90e7bcdc-4e98-4195-eb47-2c2927ef89ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set image index (between 0 to 59999) from dataset\n",
        "index = 15\n",
        "\n",
        "# set number of characters per row when printing\n",
        "np.set_printoptions(linewidth=116)\n",
        "\n",
        "# print label & image (as array)\n",
        "print(f'Label: {training_labels[index]}')\n",
        "print(f'\\nImage pixel array:\\n{training_images[index]}')\n",
        "\n",
        "# visualize the image\n",
        "plt.imshow(training_images[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YfHbiIJTWg-U",
        "outputId": "d9cf2c76-ef42-485e-fc7e-4e616d2676c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9\n",
            "\n",
            "Image pixel array:\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  85 188 146  79   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 140 202 199 255 144   0   0   0   0  11 135 157   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   3   0   0 200 187 200 191 255  51   0   0  16 208 227 236  63   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   2   0  18 233 193 206 186 219 255 171 140 255 221 203 217  43   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 107 217 195 203 204 209 216 244 255 213 207 218 228  72   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 231 216 209 204 205 217 218 214 213 201 210 215 233 128   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1   0  33 255 206 214 204 213 218 213 217 222 196 201 205 231 185   0]\n",
            " [  0   0   0   0   0   0   0   0   0   9   2   0 159 234 193 209 206 215 218 217 221 210 201 205 214 219 249   0]\n",
            " [  0   0   0   0   0   0   0   0   1   0   0  77 255 219 207 204 205 213 213 215 213 203 211 217 217 202 255  71]\n",
            " [  0   0   1   2   3   3   1   0   0   0 121 245 214 219 210 200 205 215 215 219 214 204 208 213 214 201 246 118]\n",
            " [  0   0   0   0   0   0   0   0  78 216 255 208 205 214 197 202 214 211 210 213 211 208 214 204 208 207 237 136]\n",
            " [  0   0   0   0  19  87 135 211 255 217 202 206 214 209 198 202 214 214 211 213 200 207 212 201 198 203 243 130]\n",
            " [  0  64 190 219 241 214 227 216 194 193 199 201 201 213 204 198 201 205 208 202 202 205 196 198 202 201 255  73]\n",
            " [ 23 214 209 198 198 195 200 194 212 201 201 203 204 211 204 199 199 195 194 181 187 212 208 201 212 219 245  11]\n",
            " [129 220 200 207 206 204 191 202 209 212 211 207 204 202 198 206 209 198 204 222 246 223 197 179 165 163 179   0]\n",
            " [125 232 211 205 213 212 215 216 214 207 200 197 200 197 205 204 213 226 240 176  91 163 164 159 162 173 198   0]\n",
            " [  0 146 212 229 215 213 203 198 206 203 202 202 197 196 208 227 225 112   0   0   0 185 160 161 155 167 204   0]\n",
            " [  0   0   5 117 211 237 255 244 231 225 216 220 228 255 245 122   0   0   0   0   0 231 214 212 221 201 228   6]\n",
            " [  0   2   0   0   0   0  66 116 160 191 207 207 200 120   0   0   0   0   2   0   0  95  85  79  67  51   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c1884836a40>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization: scale the data range of all values in the image array from 0-255 to 0-1"
      ],
      "metadata": {
        "id": "VtZIsiuLXTDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the pixel values\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "hqQ6ebM_YmGY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Sequential: defines a sequence of layers in neural network\n",
        "*   Flatten: turn the 28x28 pixel matrix square and turns it into 1-dimensional array\n",
        "*   Dense: add hidden layer of neurons (each layer need activation function)\n",
        "*   ReLU:\n",
        "```\n",
        "if x > 0:\n",
        "  return x\n",
        "else:\n",
        "  return 0\n",
        "```\n",
        "*   Softmax:  \n",
        "  *   takes a list of values & scale all of the elements so the sum will be equal to 1\n",
        "  *   Each scaled values will be the probability of each classes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8YBifvl3YwDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import softmax\n",
        "# build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax) # 10 MNIST fashion class as units\n",
        "])"
      ],
      "metadata": {
        "id": "tX-NA180Y0cf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZRDIzPaactNo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TdqRA9NdMZ6",
        "outputId": "d6d19edf-d1da-4029-a173-e4a734093f1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5040 - accuracy: 0.8232\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3782 - accuracy: 0.8643\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3398 - accuracy: 0.8760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3143 - accuracy: 0.8838\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2971 - accuracy: 0.8898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c1884845150>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We **evaluate** the model to see how well it work with unseen data"
      ],
      "metadata": {
        "id": "zYiC2zVUdfv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model using test set\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8xs7JCAd-Gq",
        "outputId": "eba11e9a-2e3c-41a0-dd3a-3aeb868bb0ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3550 - accuracy: 0.8749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35500916838645935, 0.8748999834060669]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notes**"
      ],
      "metadata": {
        "id": "q5PMuXbEeZtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Softmax Function** demonstration"
      ],
      "metadata": {
        "id": "sR8v96-DbAhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declare sample units & convert to tensor\n",
        "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
        "inputs = tf.convert_to_tensor(inputs)\n",
        "print(f'input to softmax function: {inputs.numpy()}')\n",
        "\n",
        "# feed inputs to softmax activation function\n",
        "outputs = tf.keras.activations.softmax(inputs)\n",
        "print(f'output of softmax function: {outputs.numpy()}')\n",
        "\n",
        "# see the sum of all values after softmax\n",
        "sum = tf.reduce_sum(outputs)\n",
        "print(f'sum of outputs: {sum}')\n",
        "\n",
        "# get index with highest value\n",
        "prediction = np.argmax(outputs)\n",
        "print(f'class with highest probability: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5NKkCk4bRTu",
        "outputId": "49c49af9-2bfc-4e32-8aad-fa8a28ae2370"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to softmax function: [[1. 3. 4. 2.]]\n",
            "output of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
            "sum of outputs: 1.0\n",
            "class with highest probability: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploration Excersises**"
      ],
      "metadata": {
        "id": "sRR5T22xelRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1\n",
        "\n",
        "Create classifications test images"
      ],
      "metadata": {
        "id": "cE4WdNaze6LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the prediction probability of the first index\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R560ZGucfIgb",
        "outputId": "aefa9099-aa62-404e-eade-51ba79f3ac1e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "[4.1228508e-05 1.1956750e-07 1.3394208e-05 8.8772190e-08 2.3697621e-06 8.1451191e-03 8.7768094e-06 9.1603361e-03\n",
            " 6.5247286e-06 9.8262197e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'predicted value: {np.argmax(classifications[0])}')\n",
        "print(f'true value: {test_labels[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ0GZp3Jfg7U",
        "outputId": "df727dc6-211a-43ab-d4cd-3c307600a234"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted value: 9\n",
            "true value: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1 Questions**\n",
        "1.   What does The list from ```print(classifications[0])``` represent?\n",
        "  *   It's the probability that this item is each of the 10 classes\n",
        "2.   How do you know that this list tells you that the item is an ankle boot?\n",
        "  *   The 10th element on the list is the biggest, and the ankle boot is labelled 9"
      ],
      "metadata": {
        "id": "lArjon3hfnB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2\n",
        "\n",
        "Look at the impact of adding more neuron"
      ],
      "metadata": {
        "id": "2wUDnCsimAsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "# create model with 1024 neurons in 1 hidden dense layer\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation=tf.nn.relu), # try 1024 neurons\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3rlllHCghnu",
        "outputId": "20ae2a17-6ecf-476e-b724-4ad2403c78d3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4689 - accuracy: 0.8313\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3582 - accuracy: 0.8680\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3217 - accuracy: 0.8824\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2975 - accuracy: 0.8898\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2788 - accuracy: 0.8955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c186807bbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0rhHAPljdVi",
        "outputId": "9747db9c-ff31-4ee2-9269-56b67b83e636"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3492 - accuracy: 0.8735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3492107391357422, 0.8734999895095825]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict first index data\n",
        "classification = model.predict(test_images)\n",
        "print(f'predicted value: {np.argmax(classifications[0])}')\n",
        "print(f'true value: {test_labels[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnyTKVSQi-DL",
        "outputId": "67722054-8dc7-4c73-8a73-fc964dcb789f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "predicted value: 9\n",
            "true value: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2 Question**\n",
        "1.   Increase to 1024 Neurons -- What's the impact?\n",
        "  *   Training takes longer, but is more accurate"
      ],
      "metadata": {
        "id": "obaXf3D5i5dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3\n",
        "\n",
        "What happened if Flatten() layer removed?"
      ],
      "metadata": {
        "id": "Fk4P9-ZbmOlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# error: `labels.shape` must equal `logits.shape` except for the last dimension"
      ],
      "metadata": {
        "id": "w5Gv76gCmn4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3 Question**\n",
        "1.   What would happen if you remove the Flatten() layer? Why do you think that's the case?\n",
        "  *   We will get an error about the shape of the data\n",
        "  *   Our data is 28x28 images currently. 28 layers of 28 neurons would be infeasible\n",
        "  *   We need to *flatten* the image into 784x1, for that case"
      ],
      "metadata": {
        "id": "-1vBfxbbmusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4\n",
        "\n",
        "What happened if the final (output) layers is different amount than 10?"
      ],
      "metadata": {
        "id": "frRIpVHLnjuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Error: Received a label value of 9 which is outside the valid range of [0, 5)"
      ],
      "metadata": {
        "id": "sTgMVNy_oUEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4 Question**\n",
        "1.   Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10?\n",
        "  *   Will get an error as soon as it finds an unexpected value\n",
        "  *   The number of neurons in the last layer should match the number of classes that is being classified\n",
        "\n"
      ],
      "metadata": {
        "id": "hmTJ2fgYoZud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5\n",
        "\n",
        "What will happen if added another layer between the single Dense layer & the output layer?"
      ],
      "metadata": {
        "id": "SI7WTLZ5p0ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stIoNHRVqLM3",
        "outputId": "21d32c78-2ec1-4acb-b109-5a943a6ccd08"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4687 - accuracy: 0.8301\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3536 - accuracy: 0.8700\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3177 - accuracy: 0.8825\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2949 - accuracy: 0.8904\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2772 - accuracy: 0.8964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c1881720670>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YFUQ6txqUgO",
        "outputId": "31e63466-cce4-49bd-9de9-6e6964e7f73c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3478 - accuracy: 0.8763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34780147671699524, 0.8762999773025513]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5 Question**\n",
        "1.   Consider the effects of additional layers in the network. What will happen if added another layer between the single Dense layer & the output layer?\n",
        "  *   There isn't a significant impact, because it's a relatively simple data\n",
        "  *   For far more complex data (example, colored images), extra layers are often necessary\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K-DQwKjxq4PP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6\n",
        "\n",
        "Trying training with different epochs"
      ],
      "metadata": {
        "id": "ZqdZP4axrfJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=15) # trying 15 epochs\n",
        "print(\"\\n\")\n",
        "\n",
        "# evaluate the model\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VirHHLCgt87A",
        "outputId": "2bc63a89-ff2b-485a-9a75-ee24b1ebec08"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4979 - accuracy: 0.8270\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3772 - accuracy: 0.8629\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3367 - accuracy: 0.8769\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3150 - accuracy: 0.8836\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2939 - accuracy: 0.8917\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2808 - accuracy: 0.8950\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2679 - accuracy: 0.8996\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2594 - accuracy: 0.9026\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2473 - accuracy: 0.9068\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2408 - accuracy: 0.9102\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2313 - accuracy: 0.9122\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2254 - accuracy: 0.9163\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2170 - accuracy: 0.9192\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2102 - accuracy: 0.9213\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2048 - accuracy: 0.9227\n",
            "\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3506084680557251, 0.885200023651123]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=30) # trying 30 epochs\n",
        "print(\"\\n\")\n",
        "\n",
        "# evaluate the model\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag3OVUEcuCVf",
        "outputId": "5c3c4822-bd31-4639-fad8-5db62727089d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5025 - accuracy: 0.8251\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3773 - accuracy: 0.8629\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3365 - accuracy: 0.8769\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3127 - accuracy: 0.8852\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2950 - accuracy: 0.8917\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2797 - accuracy: 0.8972\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2681 - accuracy: 0.9007\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2569 - accuracy: 0.9038\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2466 - accuracy: 0.9080\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2404 - accuracy: 0.9117\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2311 - accuracy: 0.9136\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2242 - accuracy: 0.9163\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2182 - accuracy: 0.9191\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2105 - accuracy: 0.9212\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2050 - accuracy: 0.9237\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2004 - accuracy: 0.9253\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1948 - accuracy: 0.9264\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1904 - accuracy: 0.9285\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1847 - accuracy: 0.9313\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1787 - accuracy: 0.9330\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1748 - accuracy: 0.9345\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1707 - accuracy: 0.9367\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1677 - accuracy: 0.9367\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1649 - accuracy: 0.9373\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1581 - accuracy: 0.9409\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1564 - accuracy: 0.9410\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1525 - accuracy: 0.9426\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1507 - accuracy: 0.9438\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1462 - accuracy: 0.9450\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1425 - accuracy: 0.9469\n",
            "\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4051 - accuracy: 0.8843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4051021635532379, 0.8842999935150146]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6 Question**\n",
        "1.   Consider the impact of training for more or less epochs. Why do you think that would be the case\n",
        "  *   15 epochs: a model with a much better loss than the one with 5\n",
        "  *   30 epochs:\n",
        "      *    loss value decrease more slowly, and sometimes increases\n",
        "      *   *evaluate* didn't improve that much. It even be slightly worse (*loss*)\n",
        "      *   it's the side effect of *overfitting*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "70hAKuUNwPTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7\n",
        "\n",
        "What if the data is not *normalized*?"
      ],
      "metadata": {
        "id": "4FOdPPCKxE9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "print(\"\\n\")\n",
        "\n",
        "# evaluate the model\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg4HqTpOxNVU",
        "outputId": "806e591f-00d1-417e-9d8e-bdf261c19baa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 2.4930 - accuracy: 0.7025\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6377 - accuracy: 0.7746\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5604 - accuracy: 0.8023\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5251 - accuracy: 0.8154\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5100 - accuracy: 0.8251\n",
            "\n",
            "\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5790 - accuracy: 0.8188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5790135264396667, 0.8187999725341797]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 7 Question**\n",
        "1.   What would be the impact of removing normalization?\n",
        "  *   Higher loss, lower accuracy, longer train time\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p_5_kGfjxU_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 8\n",
        "\n",
        "Implement callbacks to stop training on certain accuracy"
      ],
      "metadata": {
        "id": "HAzcWVlAxkfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class extends to tensorflow Keras API (Callback)\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  # overrides `on_epoch_end`\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs.get('accuracy') >= 0.6):\n",
        "      print(\"Reached 60% accuracy. Cancelling the training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "# load dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks]) # will stop if reaches 60%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ1PCrqMyUlq",
        "outputId": "259d363c-a003-4ada-c4f4-5f7ea3cc996c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.8305Reached 60% accuracy. Cancelling the training!\n",
            "1875/1875 [==============================] - 15s 7ms/step - loss: 0.4738 - accuracy: 0.8306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c1881ed33d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}